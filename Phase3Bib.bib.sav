% Encoding: UTF-8

@Article{Falconer2018,
  author       = {Falconer, Erin and Kho, David and Docherty, John P.},
  journal      = {Neuropsychiatric disease and treatment},
  title        = {Use of technology for care coordination initiatives for patients with mental health issues: a systematic literature review.},
  year         = {2018},
  issn         = {1176-6328},
  pages        = {2337--2349},
  volume       = {14},
  abstract     = {This systematic literature review investigates the use of technology for the coordination and management of mental health care with an emphasis on outcomes. Searches of MEDLINE/PubMed, Scopus, and EMBASE were conducted between January 1, 2003, and January 4, 2018, to identify articles that assessed patient outcomes associated with care coordination, evaluated technology to improve care, or discussed management of mental health care using technology. A total of 21 articles were included in a qualitative review based on the recommendations set forth by the PRISMA statement. Among the various health technologies, electronic health records were most commonly used for care coordination, with primary care being the most frequent setting. Care coordination was shown to provide easier patient access to health care providers and to improve communication between caregiver and patient, especially in cases where geographic location or distance is a challenge. Barriers to coordinated care included, but were not limited to, insufficient funding for health information technology, deficient reimbursement plans, limited access to technologies, cultural barriers, and underperforming electronic health record templates. In conclusion, many studies showed the benefit of coordinated and collaborative care through the use of technology; however, further research and development efforts are needed to continue technological innovation for advanced patient care.},
  country      = {New Zealand},
  doi          = {10.2147/NDT.S172810},
  issn-linking = {1176-6328},
  keywords     = {behavioral health; collaborative care; depression; health information technology; schizophrenia; serious mental illness},
  nlm-id       = {101240304},
  owner        = {NLM},
  pii          = {ndt-14-2337},
  pmc          = {PMC6143125},
  pmid         = {30254446},
  pubmodel     = {Electronic-eCollection},
  pubstate     = {epublish},
  revised      = {2019-11-20},
}

@Article{Stover2020,
  author          = {Stover, Angela M. and Haverman, Lotte and van Oers, Hedy A. and Greenhalgh, Joanne and Potter, Caroline M. and in Clinical Practice Implementation Science Work Group, I.S.O.Q.O.L. PROMs/PREMs},
  journal         = {Quality of life research : an international journal of quality of life aspects of treatment, care and rehabilitation},
  title           = {Using an implementation science approach to implement and evaluate patient-reported outcome measures (PROM) initiatives in routine care settings.},
  year            = {2020},
  issn            = {1573-2649},
  month           = jul,
  abstract        = {Patient-reported outcome and experience measures (PROMs/PREMs) are well established in research for many health conditions, but barriers persist for implementing them in routine care. Implementation science (IS) offers a potential way forward, but its application has been limited for PROMs/PREMs. We compare similarities and differences for widely used IS frameworks and their applicability for implementing PROMs/PREMs through case studies. Three case studies implemented PROMs: (1) pain clinics in Canada; (2) oncology clinics in Australia; and (3) pediatric/adult clinics for chronic conditions in the Netherlands. The fourth case study is planning PREMs implementation in Canadian primary care clinics. We compare case studies on barriers, enablers, implementation strategies, and evaluation. Case studies used IS frameworks to systematize barriers, to develop implementation strategies for clinics, and to evaluate implementation effectiveness. Across case studies, consistent PROM/PREM implementation barriers were technology, uncertainty about how or why to use PROMs/PREMs, and competing demands from established clinical workflows. Enabling factors in clinics were context specific. Implementation support strategies changed during pre-implementation, implementation, and post-implementation stages. Evaluation approaches were inconsistent across case studies, and thus, we present example evaluation metrics specific to PROMs/PREMs. Multilevel IS frameworks are necessary for PROM/PREM implementation given the complexity. In cross-study comparisons, barriers to PROM/PREM implementation were consistent across patient populations and care settings, but enablers were context specific, suggesting the need for tailored implementation strategies based on clinic resources. Theoretically guided studies are needed to clarify how, why, and in what circumstances IS principles lead to successful PROM/PREM integration and sustainability.},
  citation-subset = {IM},
  country         = {Netherlands},
  doi             = {10.1007/s11136-020-02564-9},
  investigator    = {Ahmed, Sara and Greenhalgh, Joanne and Gibbons, Elizabeth and Haverman, Lotte and Manalili, Kimberly and Potter, Caroline and Roberts, Natasha and Santana, Maria and Stover, Angela M and van Oers, Hedy},
  issn-linking    = {0962-9343},
  keywords        = {Clinical practice; Implementation science; Patient-reported outcome measures; Quality of life; Routine care},
  nlm-id          = {9210257},
  owner           = {NLM},
  pii             = {10.1007/s11136-020-02564-9},
  pmid            = {32651805},
  pubmodel        = {Print-Electronic},
  pubstate        = {aheadofprint},
  revised         = {2020-07-11},
}

@Article{Proctor2011,
  author          = {Proctor, Enola and Silmere, Hiie and Raghavan, Ramesh and Hovmand, Peter and Aarons, Greg and Bunger, Alicia and Griffey, Richard and Hensley, Melissa},
  journal         = {Administration and policy in mental health},
  title           = {Outcomes for implementation research: conceptual distinctions, measurement challenges, and research agenda.},
  year            = {2011},
  issn            = {1573-3289},
  month           = mar,
  pages           = {65--76},
  volume          = {38},
  abstract        = {An unresolved issue in the field of implementation research is how to conceptualize and evaluate successful implementation. This paper advances the concept of "implementation outcomes" distinct from service system and clinical treatment outcomes. This paper proposes a heuristic, working "taxonomy" of eight conceptually distinct implementation outcomes-acceptability, adoption, appropriateness, feasibility, fidelity, implementation cost, penetration, and sustainability-along with their nominal definitions. We propose a two-pronged agenda for research on implementation outcomes. Conceptualizing and measuring implementation outcomes will advance understanding of implementation processes, enhance efficiency in implementation research, and pave the way for studies of the comparative effectiveness of implementation strategies.},
  citation-subset = {IM},
  completed       = {2011-06-23},
  country         = {United States},
  doi             = {10.1007/s10488-010-0319-7},
  issn-linking    = {0894-587X},
  issue           = {2},
  keywords        = {Biomedical Research, methods, organization & administration; Diffusion of Innovation; Humans; Mental Health Services, organization & administration; Outcome and Process Assessment, Health Care, methods, organization & administration},
  nlm-id          = {8914574},
  owner           = {NLM},
  pmc             = {PMC3068522},
  pmid            = {20957426},
  pubmodel        = {Print},
  pubstate        = {ppublish},
  revised         = {2019-12-10},
}

@Article{Proctor2009,
  author          = {Proctor, Enola K. and Landsverk, John and Aarons, Gregory and Chambers, David and Glisson, Charles and Mittman, Brian},
  journal         = {Administration and policy in mental health},
  title           = {Implementation research in mental health services: an emerging science with conceptual, methodological, and training challenges.},
  year            = {2009},
  issn            = {1573-3289},
  month           = jan,
  pages           = {24--34},
  volume          = {36},
  abstract        = {One of the most critical issues in mental health services research is the gap between what is known about effective treatment and what is provided to consumers in routine care. Concerted efforts are required to advance implementation science and produce skilled implementation researchers. This paper seeks to advance implementation science in mental health services by over viewing the emergence of implementation as an issue for research, by addressing key issues of language and conceptualization, by presenting a heuristic skeleton model for the study of implementation processes, and by identifying the implications for research and training in this emerging field.},
  citation-subset = {IM},
  completed       = {2009-04-10},
  country         = {United States},
  doi             = {10.1007/s10488-008-0197-4},
  issn-linking    = {0894-587X},
  issue           = {1},
  keywords        = {Diffusion of Innovation; Evidence-Based Practice; Health Services Research, organization & administration; Humans; Information Dissemination; Mental Health Services, organization & administration, statistics & numerical data; Models, Theoretical},
  mid             = {NIHMS519797},
  nlm-id          = {8914574},
  owner           = {NLM},
  pmc             = {PMC3808121},
  pmid            = {19104929},
  pubmodel        = {Print-Electronic},
  pubstate        = {ppublish},
  revised         = {2018-12-01},
}

@Article{Kroenke2001,
  author          = {Kroenke, K. and Spitzer, R. L. and Williams, J. B.},
  journal         = {Journal of general internal medicine},
  title           = {The PHQ-9: validity of a brief depression severity measure.},
  year            = {2001},
  issn            = {0884-8734},
  month           = sep,
  pages           = {606--613},
  volume          = {16},
  abstract        = {While considerable attention has focused on improving the detection of depression, assessment of severity is also important in guiding treatment decisions. Therefore, we examined the validity of a brief, new measure of depression severity. The Patient Health Questionnaire (PHQ) is a self-administered version of the PRIME-MD diagnostic instrument for common mental disorders. The PHQ-9 is the depression module, which scores each of the 9 DSM-IV criteria as "0" (not at all) to "3" (nearly every day). The PHQ-9 was completed by 6,000 patients in 8 primary care clinics and 7 obstetrics-gynecology clinics. Construct validity was assessed using the 20-item Short-Form General Health Survey, self-reported sick days and clinic visits, and symptom-related difficulty. Criterion validity was assessed against an independent structured mental health professional (MHP) interview in a sample of 580 patients. As PHQ-9 depression severity increased, there was a substantial decrease in functional status on all 6 SF-20 subscales. Also, symptom-related difficulty, sick days, and health care utilization increased. Using the MHP reinterview as the criterion standard, a PHQ-9 score > or =10 had a sensitivity of 88% and a specificity of 88% for major depression. PHQ-9 scores of 5, 10, 15, and 20 represented mild, moderate, moderately severe, and severe depression, respectively. Results were similar in the primary care and obstetrics-gynecology samples. In addition to making criteria-based diagnoses of depressive disorders, the PHQ-9 is also a reliable and valid measure of depression severity. These characteristics plus its brevity make the PHQ-9 a useful clinical and research tool.},
  citation-subset = {IM},
  completed       = {2001-10-25},
  country         = {United States},
  doi             = {10.1046/j.1525-1497.2001.016009606.x},
  issn-linking    = {0884-8734},
  issue           = {9},
  keywords        = {Adult; Depression, diagnosis; Female; Humans; Male; Middle Aged; Psychological Tests; Reproducibility of Results; Severity of Illness Index; Surveys and Questionnaires},
  nlm-id          = {8605834},
  owner           = {NLM},
  pii             = {jgi01114},
  pmc             = {PMC1495268},
  pmid            = {11556941},
  pubmodel        = {Print},
  pubstate        = {ppublish},
  revised         = {2019-12-10},
}

@Article{Stice2000,
  author          = {Stice, E. and Telch, C. F. and Rizvi, S. L.},
  journal         = {Psychological assessment},
  title           = {Development and validation of the Eating Disorder Diagnostic Scale: a brief self-report measure of anorexia, bulimia, and binge-eating disorder.},
  year            = {2000},
  issn            = {1040-3590},
  month           = jun,
  pages           = {123--131},
  volume          = {12},
  abstract        = {This article describes the development and validation of a brief self-report scale for diagnosing anorexia nervosa, bulimia nervosa, and binge-eating disorder. Study 1 used a panel of eating-disorder experts and provided evidence for the content validity of this scale. Study 2 used data from female participants with and without eating disorders (N = 367) and suggested that the diagnoses from this scale possessed temporal reliability (mean kappa = .80) and criterion validity (with interview diagnoses; mean kappa = .83). In support of convergent validity, individuals with eating disorders identified by this scale showed elevations on validated measures of eating disturbances. The overall symptom composite also showed test-retest reliability (r = .87), internal consistency (mean alpha = .89), and convergent validity with extant eating-pathology scales. Results implied that this scale was reliable and valid in this investigation and that it may be useful for clinical and research applications.},
  citation-subset = {IM},
  completed       = {2000-08-01},
  country         = {United States},
  doi             = {10.1037//1040-3590.12.2.123},
  issn-linking    = {1040-3590},
  issue           = {2},
  keywords        = {Adolescent; Adult; Anorexia, diagnosis, psychology; Bulimia, diagnosis, psychology; Feeding and Eating Disorders, diagnosis, psychology; Female; Humans; Hyperphagia, diagnosis, psychology; Middle Aged; Predictive Value of Tests; Psychiatric Status Rating Scales, standards; Psychometrics; Reproducibility of Results},
  nlm-id          = {8915253},
  owner           = {NLM},
  pmid            = {10887758},
  pubmodel        = {Print},
  pubstate        = {ppublish},
  revised         = {2019-11-04},
}

@Article{Osman2001,
  author          = {Osman, A. and Bagge, C. L. and Gutierrez, P. M. and Konick, L. C. and Kopper, B. A. and Barrios, F. X.},
  journal         = {Assessment},
  title           = {The Suicidal Behaviors Questionnaire-Revised (SBQ-R): validation with clinical and nonclinical samples.},
  year            = {2001},
  issn            = {1073-1911},
  month           = dec,
  pages           = {443--454},
  volume          = {8},
  abstract        = {Past suicidal behaviors including ideation and attempts have been identified as significant risk factors for subsequent suicidal behavior. However, inadequate attention has been given to the development or validation of measures of past suicidal behavior. The present study examined the reliability and validity of a brief self-report measure of past suicidal behavior, the Suicidal Behaviors Questionnaire-Revised (SBQ-R). Participants included psychiatric inpatient adolescents, high school students, psychiatric inpatient adults, and undergraduates. Logistic regression analyses provided empirical support for the usefulness of the SBQ-R as a risk measure of suicide to differentiate between suicide-risk and nonsuicidal study participants. Receiver operating characteristic (ROC) analyses indicated that the most useful cutoff scores on the SBQ-R were 7 for nonsuicidal samples, and 8 for clinical samples. Both the single SBQ-R Item 1 and SBQ-R total scores are recommended for use in clinical and nonclinical settings.},
  citation-subset = {IM},
  completed       = {2002-04-09},
  country         = {United States},
  doi             = {10.1177/107319110100800409},
  issn-linking    = {1073-1911},
  issue           = {4},
  keywords        = {Adolescent; Adult; Female; Humans; Male; Regression Analysis; Reproducibility of Results; Risk Factors; Suicide, psychology, statistics & numerical data; Surveys and Questionnaires},
  nlm-id          = {9431219},
  owner           = {NLM},
  pmid            = {11785588},
  pubmodel        = {Print},
  pubstate        = {ppublish},
  revised         = {2019-12-10},
}

@Article{Ashbaugh2016,
  author          = {Ashbaugh, Andrea R. and Houle-Johnson, Stephanie and Herbert, Christophe and El-Hage, Wissam and Brunet, Alain},
  journal         = {PloS one},
  title           = {Psychometric Validation of the English and French Versions of the Posttraumatic Stress Disorder Checklist for DSM-5 (PCL-5).},
  year            = {2016},
  issn            = {1932-6203},
  pages           = {e0161645},
  volume          = {11},
  abstract        = {The purpose of this study is to assess the psychometric properties of a French version of the Posttraumatic Stress Disorder Checklist for DSM-5 (PCL-5), a self-report measure of posttraumatic stress disorder (PTSD) symptoms, and to further validate the existing English version of the measure. Undergraduate students (n = 838 English, n = 262 French) completed the PCL-5 as well as other self-report symptom measures of PTSD and depression online. Both the English and French versions PCL-5 total scores demonstrated excellent internal consistency (English: α = .95; French: α = .94), and strong convergent and divergent validity. Strong internal consistency was also observed for each of the four subscales for each version (α's > .79). Test-retest reliability for the French version of the measure was also very good (r = .89). Confirmatory factor analysis indicated that the four-factor DSM-5 model was not a good fit of the data. The seven-factor hybrid model best fit the data in each sample, but was only marginally superior to the six-factor anhedonia model. The French version of the PCL-5 demonstrated the same psychometric qualities as both the English version of the same measure and previous versions of the PCL. Thus clinicians serving French-speaking clients now have access to this highly used screening instrument. With regards to the structural validity of the PCL-5 and of the new PTSD diagnostic structure of the DSM-5, additional research is warranted. Replication of our results in clinical samples is much needed.},
  citation-subset = {IM},
  completed       = {2017-04-28},
  country         = {United States},
  doi             = {10.1371/journal.pone.0161645},
  issn-linking    = {1932-6203},
  issue           = {10},
  keywords        = {Adolescent; Adult; Checklist; Female; Humans; Language; Male; Models, Theoretical; Psychometrics; Self Report; Stress Disorders, Post-Traumatic, diagnosis},
  nlm-id          = {101285081},
  owner           = {NLM},
  pii             = {PONE-D-16-17708},
  pmc             = {PMC5056703},
  pmid            = {27723815},
  pubmodel        = {Electronic-eCollection},
  pubstate        = {epublish},
  revised         = {2019-12-10},
}

@Article{Altman1997,
  author          = {Altman, E. G. and Hedeker, D. and Peterson, J. L. and Davis, J. M.},
  journal         = {Biological psychiatry},
  title           = {The Altman Self-Rating Mania Scale.},
  year            = {1997},
  issn            = {0006-3223},
  month           = nov,
  pages           = {948--955},
  volume          = {42},
  abstract        = {We report on the development, reliability, and validity of the Altman Self-Rating Mania Scale (ASRM). The ASRM was completed during medication washout and after treatment by 22 schizophrenic, 13 schizoaffective, 36 depressed, and 34 manic patients. The Clinician-Administered Rating Scale for Mania (CARS-M) and Mania Rating Scale (MRS) were completed at the same time to measure concurrent validity. Test-retest reliability was assessed separately on 20 depressed and 10 manic patients who completed the ASRM twice during washout. Principal components analysis of ASRM items revealed three factors: mania, psychotic symptoms, and irritability. Baseline mania subscale scores were significantly higher for manic patients compared to all other diagnostic groups. Manic patients had significantly decreased posttreatment scores for all three subscales. ASRM mania subscale scores were significantly correlated with MRS total scores (r = .718) and CARS-M mania subscale scores (r = .766). Test-retest reliability for the ASRM was significant for all three subscales. Significant differences in severity levels were found for some symptoms between patient ratings on the ASRM and clinician ratings on the CARS-M. Mania subscale scores of greater than 5 on the ASRM resulted in values of 85.5% for sensitivity and 87.3% for specificity. Advantages of the ASRM over other self-rating mania scales are discussed.},
  citation-subset = {IM},
  completed       = {1998-02-05},
  country         = {United States},
  doi             = {10.1016/S0006-3223(96)00548-3},
  issn-linking    = {0006-3223},
  issue           = {10},
  keywords        = {Adult; Bipolar Disorder, diagnosis; Depressive Disorder, diagnosis; Female; Humans; Male; Middle Aged; Predictive Value of Tests; Psychiatric Status Rating Scales; Severity of Illness Index},
  nlm-id          = {0213264},
  owner           = {NLM},
  pii             = {S0006-3223(96)00548-3},
  pmid            = {9359982},
  pubmodel        = {Print},
  pubstate        = {ppublish},
  revised         = {2006-11-15},
}

@Article{Dittmann2017,
  author          = {Dittmann, Clara and Müller-Engelmann, Meike and Resick, Patricia A. and Gutermann, Jana and Stangier, Ulrich and Priebe, Kathlen and Fydrich, Thomas and Ludäscher, Petra and Herzog, Julia and Steil, Regina},
  journal         = {Behavioural and cognitive psychotherapy},
  title           = {Adherence Rating Scale for Cognitive Processing Therapy - Cognitive Only: Analysis of Psychometric Properties.},
  year            = {2017},
  issn            = {1469-1833},
  month           = nov,
  pages           = {661--670},
  volume          = {45},
  abstract        = {The assessment of therapeutic adherence is essential for accurately interpreting treatment outcomes in psychotherapy research. However, such assessments are often neglected. To fill this gap, we aimed to develop and test a scale that assessed therapeutic adherence to Cognitive Processing Therapy - Cognitive Only (CPT), which was adapted for a treatment study targeting patients with post-traumatic stress disorder and co-occurring borderline personality symptoms. Two independent, trained raters assessed 30 randomly selected treatment sessions involving seven therapists and eight patients who were treated in a multicentre randomized controlled trial. The inter-rater reliability for all items and the total score yielded good to excellent results (intraclass correlation coefficient [ICC] = 0.70 to 1.00). Cronbach's α was .56 for the adherence scale. Regarding content validity, three experts confirmed the relevance and appropriateness of each item. The adherence rating scale for the adapted version of CPT is a reliable instrument that can be helpful for interpreting treatment effects, analysing possible relationships between therapeutic adherence and treatment outcomes and teaching therapeutic skills.},
  citation-subset = {IM},
  completed       = {2018-07-06},
  country         = {United States},
  doi             = {10.1017/S1352465816000679},
  issn-linking    = {1352-4658},
  issue           = {6},
  keywords        = {Adult; Borderline Personality Disorder, complications, psychology, therapy; Cognition; Cognitive Behavioral Therapy; Female; Humans; Patient Compliance, statistics & numerical data; Psychometrics; Reproducibility of Results; Stress Disorders, Post-Traumatic, complications, psychology, therapy; Treatment Outcome; Video Recording; Young Adult; CPT; PTSD; Post-traumatic stress disorder; cognitive processing therapy; therapeutic adherence; treatment integrity},
  nlm-id          = {9418292},
  owner           = {NLM},
  pii             = {S1352465816000679},
  pmid            = {28219458},
  pubmodel        = {Print-Electronic},
  pubstate        = {ppublish},
  revised         = {2018-12-02},
}

@Comment{jabref-meta: databaseType:bibtex;}
